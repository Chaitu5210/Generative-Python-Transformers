{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba69aeb5-700e-44ca-8c62-288a7a6efd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8983cfcb-97e3-4e8b-a3d4-c59b5be4a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('WordTokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0e8ffc0-6804-4279-808f-2a58c70c07f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\"eos_token\": \"</s>\", \"bos_token\": \"<s>\", \"unk_token\": \"<unk>\", \"pad_token\": \"<pad>\", \"mask_token\": \"<mask>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07af34e0-b6bf-4c45-9a92-688b14214bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GPT2LMHeadModel.from_pretrained('GPyT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "498710ad-1235-4585-b9f1-6ce0bb2edb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWLINECHAR=\"<N>\"\n",
    "def encode_newline(inp):\n",
    "    return inp.replace(\"\\n\",NEWLINECHAR)\n",
    "def decode_newline(inp):\n",
    "    return inp.replace(NEWLINECHAR,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68ddf5f6-34b0-450f-a7cb-86552e649a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_complete(inp):\n",
    "    inp=encode_newline(inp)\n",
    "    newline_count=inp.count(NEWLINECHAR)\n",
    "    input_ids = tokenizer.encode(inp,return_tensors=\"pt\")\n",
    "    model_ouṭ = model.generate(\n",
    "        input_ids,\n",
    "        max_length=100,\n",
    "        num_beams=5,\n",
    "        temperature=0.7,\n",
    "        no_repeat_ngram_size=5,\n",
    "        num_return_sequences=3,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True)\n",
    "    sequence = model_ouṭ['sequences'][0]                                          \n",
    "    decoded=decode_newline(tokenizer.decode(sequence))\n",
    "    autocomplete=\"\"\n",
    "    split=decoded.split('\\n')\n",
    "    for s in split[:newline_count+1]:\n",
    "        autocomplete +=s+'\\n'\n",
    "    return autocomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e7aab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final AutoComplete\n",
      "import numpy as np\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_code='import numpy'\n",
    "ac=auto_complete(input_code)\n",
    "print(\"Final AutoComplete\")\n",
    "print(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d7130b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
